import numpy as np
import logging
import cv2
from typing import Dict, Any
from openpi_client.runtime import environment
import time
from gymnasium import spaces

# æ”¹ç”¨ Controller
from mkygogo.mkrobot.mk_controller import MKController

logger = logging.getLogger(__name__)

class MKRobotOpenPIEnv(environment.Environment):
    def __init__(self, prompt: str, port: str = "/dev/ttyACM0"):
        self.prompt = prompt
        camera_indices = {
                'top':   {'index': 0, 'width': 640, 'height': 480},
                'wrist': {'index': 2, 'width': 640, 'height': 360}
                }

        # ä½¿ç”¨ Controller å°è£…
        self.controller = MKController(port=port, camera_indices=camera_indices)
        self.controller.connect()
        self.step_count = 0
        # è®°å½•ä¸Šä¸€æ¬¡æ‰§è¡Œçš„åŠ¨ä½œï¼Œç”¨äºæ’å€¼è®¡ç®—
        self.prev_action = None

    @property
    def action_space(self):
        # 7ä¸ªç»´åº¦ï¼š6ä¸ªå…³èŠ‚ + 1ä¸ªå¤¹çˆª
        # èŒƒå›´å¯ä»¥å†™å¤§ä¸€ç‚¹ï¼Œä¸»è¦æ˜¯ç»´åº¦ (7,) è¦å¯¹
        return spaces.Box(low=-3.14, high=3.14, shape=(7,), dtype=np.float32)

    @property
    def observation_space(self):
        # åŒæ ·å®šä¹‰è§‚æµ‹ç©ºé—´ä¸º 7 ç»´
        return spaces.Dict({
            "state": spaces.Box(low=-3.14, high=3.14, shape=(7,), dtype=np.float32),
            "images": spaces.Dict({
                "top": spaces.Box(low=0, high=255, shape=(480, 640, 3), dtype=np.uint8),
                "wrist": spaces.Box(low=0, high=255, shape=(480, 640, 3), dtype=np.uint8),
            })
        })

    def _process_image(self, img_np, target_size=448):
        """
        å¤åˆ»è®­ç»ƒæ—¶çš„å›¾åƒå¤„ç†é€»è¾‘ï¼šä¸­å¿ƒè£å‰ª + ç¼©æ”¾
        """
        if img_np is None:
            return np.zeros((target_size, target_size, 3), dtype=np.uint8)

        h, w = img_np.shape[:2]
        min_dim = min(h, w)
        
        # 1. ä¸­å¿ƒè£å‰ª (Center Crop)
        start_h = (h - min_dim) // 2
        start_w = (w - min_dim) // 2
        img_cropped = img_np[start_h:start_h + min_dim, start_w:start_w + min_dim]
        
        # 2. ç¼©æ”¾ (Resize)
        img_resized = cv2.resize(img_cropped, (target_size, target_size), interpolation=cv2.INTER_AREA)
        
        return img_resized

    def reset(self) -> None:
        logger.info("Resetting environment...")
        self.prev_action = None
        return self.get_observation()

    def is_episode_complete(self) -> bool:
        #logger.info("is_episode_complete")
        return False

    def get_observation(self) -> Dict:

        # === â±ï¸ [DEBUG] æµ‹é€Ÿ ===
        # import time
        # now = time.time()
        # if hasattr(self, '_last_loop_time'):
        #     dt = now - self._last_loop_time
        #     fps = 1.0 / dt if dt > 0 else 0
        #     #print(f"âš¡ [Env] å®é™…å¾ªç¯é¢‘ç‡: {fps:.1f} Hz (è€—æ—¶: {dt*1000:.1f} ms)")
        # self._last_loop_time = now
        # =======================
        raw_obs = self.controller.get_observation()
        
        # å®‰å…¨è·å–
        images = raw_obs.get("images", {})
        raw_img_base = images.get("top")
        raw_img_wrist = images.get("wrist")
        
        state = raw_obs.get("state")
        
        if state is None: 
            state = np.zeros(7, dtype=np.float32)
        
        # å¯é€‰ï¼šåŠ ä¸ªå®‰å…¨æˆªæ–­ï¼Œé˜²æ­¢ä¸‡ä¸€ driver æŠ½é£å‘å¤šäº†
        if state.shape[0] > 7:
            state = state[:7]
        
        # å›¾åƒå®¹é”™
        if raw_img_base is None: raw_img_base = np.zeros((480, 640, 3), dtype=np.uint8)
        if raw_img_wrist is None: raw_img_wrist = np.zeros((360, 640, 3), dtype=np.uint8)

        img_base_processed = self._process_image(raw_img_base, target_size=448)
        img_wrist_processed = self._process_image(raw_img_wrist, target_size=448)
        
        # DEBUG View 
        try:
            self.step_count += 1
            show_base = cv2.cvtColor(img_base_processed, cv2.COLOR_RGB2BGR)
            show_wrist = cv2.cvtColor(img_wrist_processed, cv2.COLOR_RGB2BGR)
            cv2.putText(show_base, f"Step: {self.step_count}", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.imshow("Debug View: TOP", show_base)
            cv2.imshow("Debug View: WRIST", show_wrist)
            cv2.waitKey(1)
        except Exception: pass

        self.current_state = {"state": state}
        
        return {
            "image": {
                "base_0_rgb": img_base_processed,
                "left_wrist_0_rgb": img_wrist_processed,
                "right_wrist_0_rgb": img_wrist_processed,
            },
            "image_mask": {
                "base_0_rgb": np.array(True),
                "left_wrist_0_rgb": np.array(True),
                "right_wrist_0_rgb": np.array(True),
            },
            "state": state,
            "prompt": self.prompt 
        }

    # def _run_interpolation(self, start_pose: np.ndarray, target_pose: np.ndarray, steps: int, dt: float) -> None:
    #     """
    #     [è¾…åŠ©å‡½æ•°] æ‰§è¡Œæ’å€¼åŠ¨ä½œ
    #     - æœºæ¢°è‡‚ (0-5): çº¿æ€§æ’å€¼
    #     - å¤¹çˆª (6): ä¿æŒ Start çŠ¶æ€ (ä¸æ’å€¼)
    #     """
    #     if steps <= 0: return

    #     # === 1. åˆ†ç¦»å…³èŠ‚å’Œå¤¹çˆª ===
    #     start_arm = start_pose[:6]
    #     start_gripper = start_pose[6:]
        
    #     target_arm = target_pose[:6]
    #     # target_gripper = target_pose[6:] # æš‚ä¸ä½¿ç”¨ï¼Œæˆ‘ä»¬é€‰æ‹©åœ¨æ’å€¼æœŸé—´é”æ­» Start çŠ¶æ€

    #     for j in range(1, steps + 1):
    #         alpha = j / (steps + 1)
            
    #         # === 2. æœºæ¢°è‡‚æ’å€¼ (Linear) ===
    #         interp_arm = start_arm + (target_arm - start_arm) * alpha
            
    #         # === 3. å¤¹çˆªä¸æ’å€¼ ===
    #         # ç­–ç•¥ï¼šåœ¨èµ¶è·¯æœŸé—´ï¼Œä¿æŒä¸Šä¸€å¸§çš„å¤¹çˆªçŠ¶æ€ï¼Œé˜²æ­¢åŠå¼€åŠé—­
    #         # ç­‰èµ¶è·¯ç»“æŸï¼ˆè¿›å…¥ä¸»å¾ªç¯ï¼‰ï¼Œå¤¹çˆªä¼šç¬é—´å˜æˆ new_chunk çš„ç¬¬0å¸§çŠ¶æ€
    #         interp_gripper = start_gripper 
            
    #         # ç»„åˆ
    #         interp_cmd = np.concatenate([interp_arm, interp_gripper])
            
    #         self.controller.apply_action(interp_cmd)
    #         time.sleep(dt)

    def _run_interpolation(self, start_pose: np.ndarray, target_pose: np.ndarray, steps: int, dt: float) -> None:
        """
        [è¾…åŠ©å‡½æ•°] æ‰§è¡Œæ’å€¼åŠ¨ä½œ (å·²ä¼˜åŒ–æ§é¢‘)
        """
        if steps <= 0: return

        start_arm = start_pose[:6]
        start_gripper = start_pose[6:]
        target_arm = target_pose[:6]

        for j in range(1, steps + 1):
            # â±ï¸ [ä¼˜åŒ–] è®°å½•å¾ªç¯å¼€å§‹æ—¶é—´
            loop_start = time.time()
            
            alpha = j / (steps + 1)
            
            # æœºæ¢°è‡‚æ’å€¼
            interp_arm = start_arm + (target_arm - start_arm) * alpha
            # å¤¹çˆªä¿æŒ
            interp_gripper = start_gripper 
            
            interp_cmd = np.concatenate([interp_arm, interp_gripper])
            
            self.controller.apply_action(interp_cmd)
            
            # â±ï¸ [ä¼˜åŒ–] æ‰£é™¤é€šè®¯è€—æ—¶ï¼Œç²¾ç¡®ä¼‘çœ 
            elapsed = time.time() - loop_start
            sleep_time = dt - elapsed
            if sleep_time > 0:
                time.sleep(sleep_time)

    def apply_action(self, action: Dict[str, Any]) -> None:
        raw_action = action.get("actions")
        if raw_action is None: return

        if not isinstance(raw_action, np.ndarray):
            raw_action = np.array(raw_action, dtype=np.float32)

        if raw_action.ndim == 1:
            raw_action = raw_action.reshape(1, -1)
        if raw_action.ndim == 3:
            raw_action = raw_action[0]
            
        chunk_len = raw_action.shape[0]
        control_hz = 30.0
        dt = 1.0 / control_hz
        
        # æ’å€¼å‚æ•°
        INTERP_STEPS = 15
        
        # === ğŸŒŸ [æ ¸å¿ƒä¿®æ”¹] è¯»å–æ ‡ç­¾ ===
        # é»˜è®¤ä¸º True æ˜¯ä¸ºäº†å…¼å®¹æµ‹è¯•è„šæœ¬ï¼Œä½†åœ¨å®é™…è¿è¡Œä¸­ Broker ä¼šä¼  False è¿‡æ¥
        is_new_chunk = action.get("is_new_chunk", True)
        
        # å¤„ç† numpy bool ç±»å‹
        if hasattr(is_new_chunk, "item"):
            is_new_chunk = is_new_chunk.item()
            
        # åªæœ‰å½“ (æ˜¯æ–°Chunk) ä¸” (ä¸æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œ) æ—¶ï¼Œæ‰è¿›è¡Œæ’å€¼
        should_interpolate = is_new_chunk and (self.prev_action is not None)
        
        # ==========================================
        # ğŸš€ é˜¶æ®µ 1: å¤„ç† Chunk é—´çš„ç¼éš™ (æ’å€¼)
        # ==========================================
        if should_interpolate:
            print(f"ğŸŒŠ [Env] æ£€æµ‹åˆ° Chunk åˆ‡æ¢ï¼Œæ­£åœ¨æ‰§è¡Œå¹³æ»‘æ’å€¼...")
            self._run_interpolation(
                start_pose=self.prev_action, 
                target_pose=raw_action[0], 
                steps=INTERP_STEPS, 
                dt=dt
            )

        # ==========================================
        # ğŸš€ é˜¶æ®µ 2: åŸæ ·æ‰§è¡Œ (å…¨é€Ÿè¿è¡Œï¼)
        # ==========================================
        for i in range(chunk_len):
            loop_start = time.time()
            
            final_cmd = raw_action[i]
            
            self.controller.apply_action(final_cmd)   
            
            self.prev_action = final_cmd
            
            if chunk_len > 1:
                elapsed = time.time() - loop_start
                sleep_time = dt - elapsed
                if sleep_time > 0:
                    time.sleep(sleep_time)

    # def apply_action(self, action: Dict[str, Any]) -> None:
    #     raw_action = action.get("actions")
    #     if raw_action is None: return

    #     if not isinstance(raw_action, np.ndarray):
    #         raw_action = np.array(raw_action, dtype=np.float32)

    #     # ç»´åº¦æ ‡å‡†åŒ–
    #     if raw_action.ndim == 1:
    #         raw_action = raw_action.reshape(1, -1)
    #     if raw_action.ndim == 3:
    #         raw_action = raw_action[0]
            
    #     chunk_len = raw_action.shape[0]
    #     control_hz = 30.0
    #     dt = 1.0 / control_hz
        
    #     INTERP_STEPS = 10
    #     #å¤„ç† Chunk é—´çš„ç¼éš™ (æ’å€¼)
    #     if self.prev_action is not None:
    #         # è°ƒç”¨å°è£…å¥½çš„å‡½æ•°
    #         self._run_interpolation(
    #             start_pose=self.prev_action, 
    #             target_pose=raw_action[0], 
    #             steps=INTERP_STEPS, 
    #             dt=dt
    #         )
    #     for i in range(chunk_len):
    #         loop_start = time.time()           
    #         final_cmd = raw_action[i]
    #         self.controller.apply_action(final_cmd)   
    #         self.prev_action = final_cmd
            
    #         if chunk_len > 1:
    #             elapsed = time.time() - loop_start
    #             sleep_time = dt - elapsed
    #             if sleep_time > 0:
    #                 time.sleep(sleep_time)

    # def apply_action(self, action: Dict[str, Any]) -> None:
    #     """
    #     [ä¿®æ­£ç‰ˆ] åˆ†å—æµå¼æ‰§è¡Œ + å¯¹æ¥ Controller å®‰å…¨å±‚
    #     """
    #     #print(f"ğŸ› [Main] After squeeze: {raw_action.shape}")
    #     raw_action = action.get("actions")
    #     if raw_action is None: return

    #     # 1. è½¬æ¢ä¸º Numpy
    #     if not isinstance(raw_action, np.ndarray):
    #         raw_action = np.array(raw_action, dtype=np.float32)

    #     #print(f"ğŸ› [Env] Raw action shape: {raw_action.shape}, ndim={raw_action.ndim}")

    #     # 2. ç»´åº¦æ ‡å‡†åŒ– (å¤„ç† (7,) æˆ– (1, N, 7))
    #     if raw_action.ndim == 1:
    #         raw_action = raw_action.reshape(1, -1)
    #     if raw_action.ndim == 3:
    #         raw_action = raw_action[0]
    #     # æ­¤æ—¶ raw_action æ˜¯ (N, 7)ï¼Œæ¯”å¦‚ (25, 7)
    #     # 3. å¾ªç¯æ‰§è¡Œ Chunk
    #     chunk_len = raw_action.shape[0]
    #     #print(f"ğŸ› [Env] Chunk execution: len={chunk_len}")
    #     #if chunk_len > 7:
    #     #    print("ğŸ› [Env] âš ï¸ CAUTION: Chunk length > 7, checking loop logic...")

    #     control_hz = 30.0
    #     dt = 1.0 / control_hz
        
    #     for i in range(chunk_len):
    #         loop_start = time.time()
    #         #print(f"ğŸ› [Env] Loop i={i}/{chunk_len}, accessing raw_action[{i}]")
    #         # å–å‡ºå•å¸§ (7,)
    #         single_step = raw_action[i]
            
    #         if single_step.shape != (7,):
    #             print(f"ğŸ› [Env] âŒ ERROR: Single step shape wrong! {single_step.shape}")

    #         self.controller.apply_action(single_step)   
    #         # æ§é¢‘
    #         elapsed = time.time() - loop_start
    #         sleep_time = dt - elapsed
    #         if sleep_time > 0:
    #             time.sleep(sleep_time)

    def close(self):
        cv2.destroyAllWindows()
        # ç¡®ä¿ controller æœ‰ close æ–¹æ³•ï¼Œå¦‚æœæ²¡æœ‰ä¼šæŠ¥é”™
        if hasattr(self.controller, "close"):
            self.controller.close()