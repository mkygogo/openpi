import numpy as np
import logging
import cv2
from typing import Dict
from openpi_client.runtime import environment

# æ”¹ç”¨ Controller
from mkygogo.mkrobot.mk_controller import MKController

logger = logging.getLogger(__name__)

class MKRobotOpenPIEnv(environment.Environment):
    def __init__(self, prompt: str, port: str = "/dev/ttyACM0"):
        self.prompt = prompt
        camera_indices = {"top": 0, "wrist": 2}
        
        # ä½¿ç”¨ Controller å°è£…
        self.controller = MKController(port=port, camera_indices=camera_indices)
        self.controller.connect()
        self.step_count = 0

    def _process_image(self, img_np, target_size=448):
        """
        å¤åˆ»è®­ç»ƒæ—¶çš„å›¾åƒå¤„ç†é€»è¾‘ï¼šä¸­å¿ƒè£å‰ª + ç¼©æ”¾
        ä¿æŒè¾“å…¥è¾“å‡ºå‡ä¸º Numpy [H, W, C] (OpenCVæ ¼å¼)ï¼Œé¿å… Client ç«¯å¼•å…¥ Torch å¤æ‚æ€§
        """
        if img_np is None:
            return np.zeros((target_size, target_size, 3), dtype=np.uint8)

        h, w = img_np.shape[:2]
        min_dim = min(h, w)
        
        # 1. ä¸­å¿ƒè£å‰ª (Center Crop)
        start_h = (h - min_dim) // 2
        start_w = (w - min_dim) // 2
        img_cropped = img_np[start_h:start_h + min_dim, start_w:start_w + min_dim]
        
        # 2. ç¼©æ”¾ (Resize)
        img_resized = cv2.resize(img_cropped, (target_size, target_size), interpolation=cv2.INTER_AREA)
        
        return img_resized

    def reset(self) -> None:
        logger.info("Resetting environment...")
        pass

    def is_episode_complete(self) -> bool:
        return False

    def get_observation(self) -> Dict:
        raw_obs = self.controller.get_observation()
        
        raw_img_base = raw_obs["images"].get("top")
        raw_img_wrist = raw_obs["images"].get("wrist")
        state = raw_obs["state"]

        if raw_img_base is None: raw_img_base = np.zeros((480, 640, 3), dtype=np.uint8)
        if raw_img_wrist is None: raw_img_wrist = np.zeros((360, 640, 3), dtype=np.uint8)

        # è¿™é‡Œå¤„ç†åï¼Œå›¾åƒå°ºå¯¸å˜ä¸º 448x448ï¼Œä¸”å†…å®¹ç»è¿‡äº†ä¸­å¿ƒè£å‰ª
        img_base_processed = self._process_image(raw_img_base, target_size=448)
        img_wrist_processed = self._process_image(raw_img_wrist, target_size=448)

        # ==========================================================
        # ğŸ› ï¸ DEBUG: æ¸²æŸ“é€ç»™æ¨¡å‹çš„å›¾åƒ (è¿™å°±çœŸçš„æ˜¯æ¨¡å‹çœ‹åˆ°çš„ç”»é¢)
        # ==========================================================
        try:
            # OpenCV çš„ imshow é»˜è®¤éœ€è¦ BGR æ ¼å¼ï¼Œä½†æˆ‘ä»¬çš„ img_base æ˜¯ RGB
            # å¦‚æœç›´æ¥ showï¼Œçº¢è‰²ç‰©ä½“ä¼šå˜è“ã€‚ä¸ºäº†æ–¹ä¾¿äººçœ¼è§‚å¯Ÿï¼Œæˆ‘ä»¬è½¬å› BGR æ˜¾ç¤ºã€‚
            # (è¿™ä¸å½±å“é€ç»™æ¨¡å‹çš„æ•°æ®ï¼Œåªå½±å“æ˜¾ç¤ºçš„çª—å£)
            show_base = cv2.cvtColor(img_base_processed, cv2.COLOR_RGB2BGR)
            show_wrist = cv2.cvtColor(img_wrist_processed, cv2.COLOR_RGB2BGR)

            # åœ¨å›¾ç‰‡ä¸Šæ‰“å°å½“å‰çš„ Stepï¼Œæ–¹ä¾¿æˆªå›¾åˆ†æ
            cv2.putText(show_base, f"TOP Step: {self.step_count}", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºçª—å£
            cv2.imshow("Debug View: TOP (Processed)", show_base)
            cv2.imshow("Debug View: WRIST (Processed)", show_wrist)
            
            # å¿…é¡»è°ƒç”¨ waitKey æ‰èƒ½åˆ·æ–°çª—å£ï¼Œ1ms å»¶è¿Ÿ
            cv2.waitKey(1)
        except Exception as e:
            print(f"Display Error: {e}")
        # ==========================================================


        # ä¿å­˜çŠ¶æ€ä¾› debug ä½¿ç”¨
        self.current_state = state

        return {
            "image": {
                "base_0_rgb": img_base_processed,
                "left_wrist_0_rgb": img_wrist_processed,
                "right_wrist_0_rgb": img_wrist_processed,
            },
            "image_mask": {
                "base_0_rgb": np.array(True),
                "left_wrist_0_rgb": np.array(True),
                "right_wrist_0_rgb": np.array(True),
            },
            "state": state,
            "prompt": self.prompt 
        }

    def apply_action(self, action: Dict) -> None:
        raw_action = action.get("actions")
        if raw_action is not None:
            if hasattr(raw_action, 'cpu'): raw_action = raw_action.cpu().numpy()
            if hasattr(raw_action, 'numpy'): raw_action = raw_action.numpy()
            
            # --- ğŸ›¡ï¸ è°ƒè¯•æ—¥å¿—: çŠ¶æ€ vs åŠ¨ä½œ ---
            # æ¯ 10 æ­¥æ‰“å°ä¸€æ¬¡ï¼Œé¿å…åˆ·å±å¤ªå¿«
            self.step_count += 1
            if self.step_count % 10 == 0:
                # æ‰“å°å‰ 3 ä¸ªå…³èŠ‚çš„è§’åº¦å¯¹æ¯”
                curr = self.current_state
                act = raw_action
                diff = act - curr
                with np.printoptions(precision=3, suppress=True, linewidth=200):
                    # é‡ç‚¹å…³æ³¨ Act çš„æœ€åä¸€ä½ï¼šå¦‚æœæ˜¯ 1.0 (æˆ–æ¥è¿‘æœ€å¤§å€¼) ä»£è¡¨é—­åˆï¼Œ0.0 ä»£è¡¨å¼ å¼€
                    logger.info(f"Step {self.step_count}")
                    logger.info(f"  Act  (Model): {act}")  
                    logger.info(f"  Curr (Robot): {curr}")
                
                # å¦‚æœå·®å€¼éå¸¸å¤§ (ä¾‹å¦‚ > 0.5 å¼§åº¦)ï¼Œè¯´æ˜æ¨¡å‹è¾“å‡ºçš„å’Œå½“å‰ä½ç½®å®Œå…¨ä¸åŒ¹é…
                if np.max(np.abs(diff)) > 0.5:
                    logger.warning("ğŸš¨ åŠ¨ä½œåå·®è¿‡å¤§ï¼å¯èƒ½æ˜¯åæ ‡ç³»ä¸åŒ¹é…æˆ–æ¨¡å‹æœªæ”¶æ•›ã€‚")

            # å‘é€ç»™ Controller æ‰§è¡Œ
            self.controller.apply_action(np.array(raw_action))

    def close(self):
        cv2.destroyAllWindows()
        self.controller.close()